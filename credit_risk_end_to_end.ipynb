{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac47fe1c",
   "metadata": {},
   "source": [
    "\n",
    "# Credit Risk Scoring Notebook (Production-Oriented)\n",
    "\n",
    "This notebook builds a credit risk model end-to-end using realistic, production-minded steps:\n",
    "\n",
    "1. Load and join multiple data sources (application data + bureau credit history).\n",
    "2. Engineer applicant-level features by aggregating bureau records.\n",
    "3. Handle missing data, scaling, and categorical encoding using **scikit-learn Pipelines**.\n",
    "4. Train a baseline XGBoost model on a consistent preprocessing pipeline.\n",
    "5. Evaluate using credit-relevant metrics (ROC-AUC, PR-AUC, Brier score, confusion matrix at business threshold).\n",
    "6. Generate interpretability artifacts (permutation importance).\n",
    "7. Save the trained end-to-end pipeline for deployment in an API.\n",
    "\n",
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed75a75",
   "metadata": {},
   "source": [
    "## 1. Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843804d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    average_precision_score,\n",
    "    brier_score_loss,\n",
    "    ConfusionMatrixDisplay,\n",
    "    classification_report\n",
    ")\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "import xgboost as xgb\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb35152",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Load Raw Tables\n",
    "\n",
    "Assumptions:\n",
    "- `application_train` contains one row per applicant/loan request plus the target `TARGET` (1 = default, 0 = repaid).\n",
    "- `bureau` contains *external credit lines* for each applicant; one row per credit line.  \n",
    "  We must **aggregate** this to applicant level before joining, otherwise we duplicate customers.\n",
    "\n",
    "Replace the placeholders below with your actual DataFrames if already loaded in memory.  \n",
    "If they are already defined in the session, you can skip redefining them here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3ad592",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# If you've already loaded your CSVs earlier in the session, comment this block out\n",
    "# and just make sure you have:\n",
    "# application_train, bureau, previous_application, etc.\n",
    "\n",
    "# Example (adjust paths as needed):\n",
    "# application_train = pd.read_csv('data/application_train.csv')\n",
    "# bureau = pd.read_csv('data/bureau.csv')\n",
    "# previous_application = pd.read_csv('data/previous_application.csv')\n",
    "\n",
    "df_application = application_train.copy()\n",
    "df_bureau = bureau.copy()\n",
    "df_prev = previous_application.copy()  # kept for future feature work (not used yet)\n",
    "\n",
    "print('application_train shape:', df_application.shape)\n",
    "print('bureau shape:', df_bureau.shape)\n",
    "print('previous_application shape:', df_prev.shape)\n",
    "df_application.head().T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e7d6a2",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Feature Engineering: Aggregate Bureau Credit History Per Applicant\n",
    "\n",
    "We DO NOT directly join `bureau` to `application_train` row-by-row because `bureau` has multiple rows per applicant (`SK_ID_CURR`). That would explode the rows and leak information.\n",
    "\n",
    "Instead, we aggregate bureau into applicant-level summaries:\n",
    "\n",
    "- `bureau_num_loans`: how many credit lines exist for this applicant\n",
    "- `bureau_total_credit`: total outstanding credit across all those lines\n",
    "- `bureau_active_loans`: how many of those are currently active\n",
    "- `bureau_avg_credit`: mean credit size\n",
    "\n",
    "These are classic risk features: exposure, leverage, and active obligations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8871a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bureau_agg = (\n",
    "    df_bureau.groupby('SK_ID_CURR').agg(\n",
    "        bureau_num_loans=('SK_ID_BUREAU', 'count'),\n",
    "        bureau_total_credit=('AMT_CREDIT_SUM', 'sum'),\n",
    "        bureau_active_loans=('CREDIT_ACTIVE', lambda x: (x == 'Active').sum() ),\n",
    "        bureau_avg_credit=('AMT_CREDIT_SUM', 'mean')\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "print('bureau_agg shape:', bureau_agg.shape)\n",
    "bureau_agg.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00659ceb",
   "metadata": {},
   "source": [
    "\n",
    "## 4. Merge Engineered Features Into Application Data\n",
    "\n",
    "We now LEFT JOIN the aggregated bureau info back into the main application table.\n",
    "\n",
    "- We keep **all** applicants from the application data (even if they have no bureau history).\n",
    "- Missing bureau values will become NaN and later will be imputed.\n",
    "\n",
    "We then select a first working subset of interpretable features for the baseline model.\n",
    "You can always add more features later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555f757e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "feature_df = df_application.merge(\n",
    "    bureau_agg,\n",
    "    how='left',           # keep all applicants, even if no bureau history\n",
    "    on='SK_ID_CURR'\n",
    ")\n",
    "\n",
    "selected_cols = [\n",
    "    'SK_ID_CURR',\n",
    "    'TARGET',                 # label\n",
    "    'AMT_INCOME_TOTAL',\n",
    "    'AMT_CREDIT',\n",
    "    'AMT_ANNUITY',\n",
    "    'DAYS_EMPLOYED',\n",
    "    'DAYS_BIRTH',\n",
    "    'NAME_EDUCATION_TYPE',\n",
    "    'NAME_FAMILY_STATUS',\n",
    "    'OCCUPATION_TYPE',\n",
    "    # engineered bureau features:\n",
    "    'bureau_num_loans',\n",
    "    'bureau_total_credit',\n",
    "    'bureau_active_loans',\n",
    "    'bureau_avg_credit',\n",
    "]\n",
    "\n",
    "model_df = feature_df[selected_cols].copy()\n",
    "print('model_df shape:', model_df.shape)\n",
    "model_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b9247b",
   "metadata": {},
   "source": [
    "\n",
    "## 5. Quick EDA for Storytelling / Portfolio\n",
    "\n",
    "### 5.1 Class imbalance\n",
    "In credit risk, defaults are rare. We visualize the class distribution.\n",
    "\n",
    "### 5.2 Income distribution by target\n",
    "Is lower income associated with higher default?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3300a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 5.1 Target distribution\n",
    "y_full = model_df['TARGET'].astype(int)\n",
    "plt.figure(figsize=(4,3))\n",
    "sns.countplot(x=y_full)\n",
    "plt.title('Target distribution: Default vs No Default')\n",
    "plt.xlabel('TARGET (1 = default)')\n",
    "plt.ylabel('Count')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('Default rate:', y_full.mean())\n",
    "\n",
    "# 5.2 Income by default status\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.kdeplot(\n",
    "    data=model_df,\n",
    "    x='AMT_INCOME_TOTAL',\n",
    "    hue='TARGET',\n",
    "    common_norm=False,\n",
    "    fill=True,\n",
    "    alpha=0.4\n",
    ")\n",
    "plt.xlim(0, model_df['AMT_INCOME_TOTAL'].quantile(0.95))\n",
    "plt.title('Income distribution by default status')\n",
    "plt.xlabel('AMT_INCOME_TOTAL')\n",
    "plt.ylabel('Density')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9451837a",
   "metadata": {},
   "source": [
    "\n",
    "## 6. Train / Test Split\n",
    "\n",
    "We keep 20% as hold-out test data and stratify by `TARGET` to preserve the default rate.\n",
    "We also drop ID columns (`SK_ID_CURR`) from the features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf13eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "target_col = 'TARGET'\n",
    "id_col = 'SK_ID_CURR'\n",
    "\n",
    "y = model_df[target_col].astype(int)\n",
    "X = model_df.drop(columns=[target_col, id_col])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.20,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "X_train.shape, X_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056d1148",
   "metadata": {},
   "source": [
    "\n",
    "## 7. Preprocessing Pipeline\n",
    "\n",
    "We build a `ColumnTransformer` that:\n",
    "- imputes missing numeric values with median\n",
    "- scales numeric features\n",
    "- imputes missing categoricals with the most frequent value\n",
    "- one-hot encodes categoricals\n",
    "\n",
    "This avoids `dropna()`, keeps signal from missingness, and produces consistent transformations that we can reuse in production.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a415e78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Identify numeric vs categorical columns\n",
    "num_cols = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols = [c for c in X_train.columns if c not in num_cols]\n",
    "\n",
    "num_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "cat_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('ohe', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', num_pipe, num_cols),\n",
    "    ('cat', cat_pipe, cat_cols),\n",
    "])\n",
    "preprocessor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e0d316",
   "metadata": {},
   "source": [
    "\n",
    "## 8. Model Training (XGBoost in a Pipeline)\n",
    "\n",
    "We wrap preprocessing + model into a single `Pipeline`.  \n",
    "This guarantees:\n",
    "- no data leakage\n",
    "- same transformations at training and inference\n",
    "- easy deployment via `joblib.dump`\n",
    "\n",
    "We start with a reasonable XGBoost config (not yet tuned). Later, you could plug this pipeline into GridSearchCV / RepeatedStratifiedKFold.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020a2134",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf_xgb = xgb.XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='logloss',\n",
    "    random_state=42,\n",
    "    n_estimators=400,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=4,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    ")\n",
    "\n",
    "model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('clf', clf_xgb),\n",
    "])\n",
    "\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fb80e0",
   "metadata": {},
   "source": [
    "\n",
    "## 9. Evaluation\n",
    "\n",
    "For credit risk we report:\n",
    "- ROC-AUC (discrimination power)\n",
    "- PR-AUC (useful under class imbalance)\n",
    "- Brier score (calibration of probabilities)\n",
    "- Confusion matrix at a chosen business threshold (e.g. 0.30)\n",
    "- Classification report (precision/recall/F1 on that threshold)\n",
    "\n",
    "In practice, business chooses a threshold to control approval rate and expected loss — not always 0.5.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66e0a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "roc = roc_auc_score(y_test, y_proba)\n",
    "pr_auc = average_precision_score(y_test, y_proba)\n",
    "brier = brier_score_loss(y_test, y_proba)\n",
    "\n",
    "print('ROC-AUC:', roc)\n",
    "print('PR-AUC:', pr_auc)\n",
    "print('Brier score:', brier)\n",
    "\n",
    "# pick a decision threshold\n",
    "threshold = 0.30\n",
    "y_pred = (y_proba >= threshold).astype(int)\n",
    "\n",
    "print('\\nClassification report @ threshold =', threshold)\n",
    "print(classification_report(\n",
    "    y_test,\n",
    "    y_pred,\n",
    "    target_names=['No Default', 'Default']\n",
    "))\n",
    "\n",
    "ConfusionMatrixDisplay.from_predictions(\n",
    "    y_test,\n",
    "    y_pred,\n",
    "    cmap='Blues',\n",
    "    values_format='d',\n",
    "    display_labels=['No Default', 'Default']\n",
    ")\n",
    "plt.title(f'Confusion matrix @ threshold={threshold}')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e0fb45",
   "metadata": {},
   "source": [
    "\n",
    "## 10. Model Explainability (Permutation Importance)\n",
    "\n",
    "Permutation Importance answers: *\"If I randomly shuffle this feature, how much worse does the model perform?\"*\n",
    "\n",
    "This:\n",
    "- works with any model (LogReg, XGBoost, LightGBM, ...)\n",
    "- is easy to explain to stakeholders and auditors\n",
    "- helps justify why the model rejected or priced a customer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3f384a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "r = permutation_importance(\n",
    "    model,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    n_repeats=5,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    scoring='roc_auc'\n",
    ")\n",
    "\n",
    "feat_names = model.named_steps['preprocessor'].get_feature_names_out()\n",
    "imp_df = pd.DataFrame({\n",
    "    'feature': feat_names,\n",
    "    'importance': r.importances_mean\n",
    "}).sort_values('importance', ascending=False).head(15)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.barplot(\n",
    "    data=imp_df,\n",
    "    y='feature',\n",
    "    x='importance'\n",
    ")\n",
    "plt.title('Top 15 features driving model performance')\n",
    "plt.xlabel('Permutation importance (Δ ROC-AUC)')\n",
    "plt.ylabel('')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "imp_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acad21d",
   "metadata": {},
   "source": [
    "\n",
    "## 11. Save the Full Pipeline for Deployment\n",
    "\n",
    "We export the entire preprocessing+model pipeline.\n",
    "This artifact can be loaded by a FastAPI service (`serve/app.py`) and used to score new applicants.\n",
    "\n",
    "In production, you would version this file with a timestamp or a model registry.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88809845",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.makedirs('artifacts', exist_ok=True)\n",
    "joblib.dump(model, 'artifacts/best_pipeline.joblib')\n",
    "\n",
    "print('Saved pipeline to artifacts/best_pipeline.joblib')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f27f2e5",
   "metadata": {},
   "source": [
    "\n",
    "\n",
  
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
